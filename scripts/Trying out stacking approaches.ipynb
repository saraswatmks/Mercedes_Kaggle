{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manish/anaconda2/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"new_features/full_train_v3.csv\")\n",
    "test = pd.read_csv(\"new_features/full_test_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['y'].values\n",
    "y_mean = np.mean(y_train)\n",
    "id_test = test.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_train = len(train)\n",
    "df_all = pd.concat([train, test])\n",
    "df_all.drop(['ID','y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingCVRegressorAveraged(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, regressors, meta_regressor, n_folds=5):\n",
    "        self.regressors = regressors\n",
    "        self.meta_regressor = meta_regressor\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.regr_ = [list() for x in self.regressors]\n",
    "        self.meta_regr_ = clone(self.meta_regressor)\n",
    "\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.regressors)))\n",
    "\n",
    "        for i, clf in enumerate(self.regressors):\n",
    "            for train_idx, holdout_idx in kfold.split(X, y):\n",
    "                instance = clone(clf)\n",
    "                self.regr_[i].append(instance)\n",
    "\n",
    "                instance.fit(X[train_idx], y[train_idx])\n",
    "                y_pred = instance.predict(X[holdout_idx])\n",
    "                out_of_fold_predictions[holdout_idx, i] = y_pred\n",
    "\n",
    "        self.meta_regr_.fit(out_of_fold_predictions, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([r.predict(X) for r in regrs]).mean(axis=1)\n",
    "            for regrs in self.regr_\n",
    "        ])\n",
    "        return self.meta_regr_.predict(meta_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingCVRegressorRetrained(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, regressors, meta_regressor, n_folds=5, use_features_in_secondary=False):\n",
    "        self.regressors = regressors\n",
    "        self.meta_regressor = meta_regressor\n",
    "        self.n_folds = n_folds\n",
    "        self.use_features_in_secondary = use_features_in_secondary\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.regr_ = [clone(x) for x in self.regressors]\n",
    "        self.meta_regr_ = clone(self.meta_regressor)\n",
    "\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.regressors)))\n",
    "\n",
    "        # Create out-of-fold predictions for training meta-model\n",
    "        for i, regr in enumerate(self.regr_):\n",
    "            for train_idx, holdout_idx in kfold.split(X, y):\n",
    "                instance = clone(regr)\n",
    "                instance.fit(X[train_idx], y[train_idx])\n",
    "                out_of_fold_predictions[holdout_idx, i] = instance.predict(X[holdout_idx])\n",
    "\n",
    "        # Train meta-model\n",
    "        if self.use_features_in_secondary:\n",
    "            self.meta_regr_.fit(np.hstack((X, out_of_fold_predictions)), y)\n",
    "        else:\n",
    "            self.meta_regr_.fit(out_of_fold_predictions, y)\n",
    "        \n",
    "        # Retrain base models on all data\n",
    "        for regr in self.regr_:\n",
    "            regr.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            regr.predict(X) for regr in self.regr_\n",
    "        ])\n",
    "\n",
    "        if self.use_features_in_secondary:\n",
    "            return self.meta_regr_.predict(np.hstack((X, meta_features)))\n",
    "        else:\n",
    "            return self.meta_regr_.predict(meta_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingRegressor(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, regressors):\n",
    "        self.regressors = regressors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.regr_ = [clone(x) for x in self.regressors]\n",
    "        \n",
    "        # Train base models\n",
    "        for regr in self.regr_:\n",
    "            regr.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            regr.predict(X) for regr in self.regr_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en = make_pipeline(RobustScaler(), SelectFromModel(Lasso(alpha=0.03)), ElasticNet(alpha=0.001, l1_ratio=0.1))\n",
    "    \n",
    "rf = RandomForestRegressor(n_estimators=250, n_jobs=4, min_samples_split=25, min_samples_leaf=25, max_depth=3)\n",
    "                           \n",
    "et = ExtraTreesRegressor(n_estimators=100, n_jobs=4, min_samples_split=25, min_samples_leaf=35, max_features=150)\n",
    "\n",
    "xgbm = xgb.sklearn.XGBRegressor(max_depth=4, learning_rate=0.005, subsample=0.9, base_score=y_mean,\n",
    "                                objective='reg:linear', n_estimators=1000)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_avg = StackingCVRegressorAveraged((en, rf, et), ElasticNet(l1_ratio=0.1, alpha=1.4))\n",
    "\n",
    "stack_with_feats = StackingCVRegressorRetrained((en, rf, et), xgbm, use_features_in_secondary=True)\n",
    "\n",
    "stack_retrain = StackingCVRegressorRetrained((en, rf, et), ElasticNet(l1_ratio=0.1, alpha=1.4))\n",
    "\n",
    "averaged = AveragingRegressor((en, rf, et, xgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = cross_val_score(en, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"ElasticNet score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(rf, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"RandomForest score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(et, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"ExtraTrees score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(xgbm, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"XGBoost score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(averaged, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"Averaged base models score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(stack_with_feats, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"Stacking (with primary feats) score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(stack_retrain, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"Stacking (retrained) score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "                 \n",
    "results = cross_val_score(stack_avg, train.values, y_train, cv=5, scoring='r2')\n",
    "print(\"Stacking (averaged) score: %.4f (%.4f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
